---
title: "Untitled"
author: "Lux"
date: '21 04 2020 '
output: html_document
---

```{r setup, include=FALSE, message=F, warning=F}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(webhoser)
library(data.table)
library(ggplot2)
library(lubridate)
library(grid)
library(wordcloud)
library(reshape2)
library(igraph)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)

```

## Analiza teksta


## Uvoz podataka



```{r PODATCI, message=F, warning=F}

# UČITAJ ČLANKE

#remotes::install_github("news-r/webhoser")
#require(webhoser)




# UČITAJ LEKSIKONE

CroSentilex_n <- read.delim("C:/Users/msagovac/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
                                   header = FALSE,
                                   sep = " ",
                                   stringsAsFactors = FALSE,
                                   fileEncoding = "UTF-8")  %>%
                   rename(word = "V1", sentiment = "V2" ) %>%
                   mutate(brija = "NEG")
 
 CroSentilex_p  <- read.delim("C:/Users/msagovac/Dropbox/Mislav@Luka/crosentilex-positives.txt",
                                   header = FALSE,
                                   sep = " ",
                                   stringsAsFactors = FALSE,
                                   fileEncoding = "UTF-8") %>%
                    rename(word = "V1", sentiment = "V2" ) %>%
                    mutate(brija = "POZ")
 
 Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
 
 
 CroSentilex_Gold  <- read.delim2("C:/Users/msagovac/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
                                 header = FALSE,
                                 sep = " ",
                                 stringsAsFactors = FALSE) %>%
                    rename(word = "V1", sentiment = "V2" ) 

 Encoding(CroSentilex_Gold$word) <- "UTF-8"
 CroSentilex_Gold[1,1] <- "dati"
 CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
 CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
 CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
 
 
 
 
 stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
my_stop_words <- tibble(
  word = c(
    "jedan",
    "e","prvi", "dva","dvije","drugi",
    "tri","treći","pet","kod",
    "ove","ova",  "ovo","bez", "kod",
    "evo","oko",  "om", "ek",
    "mil","tko","šest", "sedam",
    "osam",   "čim", "zbog",
    "prema", "dok","zato", "koji", 
    "im", "čak","među", "tek",
    "koliko", "tko","kod","poput", 
    "baš", "dakle", "osim", "svih", 
    "svoju", "odnosno", "gdje",
    "kojoj", "ovi", "toga",
     "ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"
  ),
  lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
  bind_rows(stopwords_cro)


```


```{r RIJEČI, message=F, warning=F}

# UREDI ČLANKE

newsCOVID <- cro_corona_news %>% 
  as.data.frame() %>%
  select(url, author, published, title, text, thread.site) %>%
  mutate(published = gsub("T.*","",published) ) %>%
  mutate(published = as.Date(published,"%Y-%m-%d")) %>%
  mutate(clanak = 1:n()) %>%
  group_by(thread.site) %>%
  mutate(domenaBr = n()) %>% 
  ungroup()

glimpse(newsCOVID)


# TOKENIZACIJA

newsCOVID %>% 
  unnest_tokens(word, text) -> newsCOVID_token 

glimpse(newsCOVID_token)

newsCOVID_token %>%
  head(10)

newsCOVID_token %>% 
  sample_n(.,10)

# DESKRIPTIVNI PREGLED PODATAKA


## Ukloni "stop words"
newsCOVID_token %>% 
  anti_join(stop_corpus, by = "word") %>%
  mutate(word = gsub("\\d+", NA, word)) %>%
  mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> newsCOVID_tokenTidy

## Najčešće riječi
newsCOVID_tokenTidy %>%
  count(word, sort = T) %>%
  head(25)

## Vizualizacija najčešćih riječi
newsCOVID_tokenTidy %>%
  count(word, sort = T) %>%
  filter(n > 5000) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

## Vremenski raspon
range(newsCOVID_token$published)

## Vizualizacija najčešćih riječi kroz vrijeme
newsCOVID_tokenTidy %>%
   mutate(Datum = floor_date(published, "day")) %>%
   group_by(Datum) %>%
   count(word) %>% 
   mutate(gn = sum(n)) %>%
   filter(word %in%  c("stožera", "mjere", "virus", "kriza")) %>%
   ggplot(., aes(Datum,  n / gn)) + 
   geom_point() +
   ggtitle("Učestalost korištenja riječi u člancima o pandemiji COVID-19") +
   ylab("% ukupnih riječi") +
   geom_smooth() +
   facet_wrap(~ word, scales = "free_y") +
   scale_y_continuous(labels = scales::percent_format())


## Broj domena
newsCOVID_tokenTidy %>% 
  summarise(Domena = n_distinct(thread.site))

## Pregled domena
newsCOVID_tokenTidy %>%
  group_by(thread.site) %>%
  summarise() %>%
  head(50)

## Broj članaka po domeni

newsCOVID %>% 
  group_by(thread.site) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>% 
  head(20)

newsCOVID %>% 
  group_by(thread.site) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>% 
  top_n(6) %>%
  select(thread.site) %>%
  pull() -> topPortali

## Broj članaka po domeni kroz vrijeme

newsCOVID %>% 
   mutate(Datum = floor_date(published, "day")) %>%
   group_by(Datum) %>%
   count(thread.site) %>% 
   mutate(gn = sum(n)) %>%
   ungroup ()%>% 
   filter(thread.site %in% topPortali) %>%
   group_by(Datum, thread.site) %>%
   ggplot(., aes(Datum,  n / gn)) + 
   geom_point() +
   ggtitle("Članci o pandemiji COVID-19 na najvažnijim RH portalima") +
   ylab("% ukupno objavljenih članaka") +
   geom_smooth() +
   facet_wrap(~ thread.site, scales = "free_y") +
   scale_y_continuous(labels = scales::percent_format())
   
  

```


```{r SENTIMENT, message=F, warning=F}

## Pregled leksikona
CroSentilex_n %>% sample_n(10)
CroSentilex_p %>% sample_n(10)
Crosentilex_sve %>% sample_n(10)
CroSentilex_Gold %>% sample_n(10)

## Kretanje sentimenta kroz vrijeme
vizualiziraj_sentiment <- function(dataset, frq = "day") {

dataset %>%
  inner_join( Crosentilex_sve, by = "word") %>%
  filter(!is.na(word)) %>%
  select(word, brija, published, sentiment) %>% 
  unique() %>%
  spread(. , brija, sentiment) %>%
  mutate(sentiment = POZ - NEG) %>%
  select(word, published, sentiment) %>% 
  group_by(word) %>% 
  mutate(count = n()) %>%
  arrange(desc(count)) %>%
  mutate( score = sentiment*count) %>%
  ungroup() %>%
  group_by(published) %>%
  arrange(desc(published)) -> sm

 
sm %>%
  select(published, score) %>%
  group_by(Datum = floor_date(published, frq)) %>%
  summarise(Dnevni_sent = sum(score, na.rm = TRUE)) %>%
  ggplot(., aes(Datum, Dnevni_sent)) +
  geom_bar(stat = "identity") + 
  ggtitle(paste0("Sentiment kroz vrijeme;frekvencija podataka:", frq)) +
  ylab("SentimentScore") -> gg_sentiment_kroz_vrijeme_qv


gg_sentiment_kroz_vrijeme_qv

}
vizualiziraj_sentiment(newsCOVID_tokenTidy,"day")
## Doprinos sentimentu
doprinos_sentimentu <- function(dataset, no = n) {
dataset %>%
  anti_join(CroSentilex_Gold, by = "word") %>% 
  count(word, sentiment,sort = TRUE) %>% 
  group_by(sentiment) %>%
  top_n(no) %>%
  ungroup() %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRALNO",
                                 sentiment == 1 ~ "NEGATIVNO",
                                 sentiment == 2 ~ "POZITIVNO")) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  ggtitle( "Doprinos sentimentu") +
  labs( x = "Riječ", y = "Broj riječi") +
  facet_wrap(~ sentiment, scales = "free_y") +
  coord_flip() -> gg_doprinos_sentimentu
  
 gg_doprinos_sentimentu
 
}
doprinos_sentimentu(newsCOVID_tokenTidy,15)

## WordCloud(vulgaris)
newsCOVID_tokenTidy %>%
  anti_join(CroSentilex_Gold,by="word") %>% 
  count(word) %>% 
  arrange(desc(n)) %>%
  top_n(100) %>%
  with(wordcloud(word, n, max.words = 80))

## ComparisonCloud
newsCOVID_tokenTidy %>%
  inner_join(CroSentilex_Gold,by="word") %>% 
  count(word, sentiment) %>% 
  top_n(200) %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
                                 sentiment == 1 ~ "-",
                                 sentiment == 2 ~ "+")) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
                   max.words = 120)

## Najnegativniji portal

wCount <- newsCOVID_tokenTidy %>% 
  group_by(thread.site) %>%
  summarise(word = n())

CroSentilex_Gold_neg <- CroSentilex_Gold %>% filter(sentiment == 1)
CroSentilex_Gold_poz <- CroSentilex_Gold %>% filter(sentiment == 2)


newsCOVID_tokenTidy %>% 
  semi_join(CroSentilex_Gold_neg, by= "word") %>%
  group_by(thread.site) %>% 
  summarise(negWords = n()) %>%
  left_join(wCount, by = "thread.site") %>%
  mutate(negativnostIndex = (negWords/word)*100) %>%
  arrange(desc(negativnostIndex))
  
newsCOVID_tokenTidy %>% 
  semi_join(CroSentilex_Gold_poz, by= "word") %>%
  group_by(thread.site) %>% 
  summarise(pozWords = n()) %>%
  left_join(wCount, by = "thread.site") %>%
  mutate(pozitivnostIndex = (pozWords/word)*100) %>%
  arrange(desc(pozitivnostIndex))  

### Veliki portali 

newsCOVID %>%
  group_by(thread.site) %>%
  count %>%
  arrange(desc(n)) %>%
  head(10) %>%
  pull(thread.site) -> najveceDomene




newsCOVID_tokenTidy %>% 
  filter(thread.site %in% najveceDomene) %>%
  semi_join(CroSentilex_Gold_neg, by= "word") %>%
  group_by(thread.site) %>% 
  summarise(negWords = n()) %>%
  left_join(wCount, by = "thread.site") %>%
  mutate(negativnostIndex = (negWords/word)*100) %>%
  arrange(desc(negativnostIndex))


newsCOVID_tokenTidy %>% 
  filter(thread.site %in% najveceDomene) %>%
  semi_join(CroSentilex_Gold_poz, by= "word") %>%
  group_by(thread.site) %>% 
  summarise(pozWords = n()) %>%
  left_join(wCount, by = "thread.site") %>%
  mutate(pozitivnostIndex = (pozWords/word)*100) %>%
  arrange(desc(pozitivnostIndex))  

```


```{r FREKVENCIJA, message=F, warning=F}

domenaWords <- newsCOVID %>%
  unnest_tokens(word,text) %>% 
  count(thread.site, word, sort = T)
  
ukupnoWords <- domenaWords %>%
  group_by(thread.site) %>%
  summarise(totWords = sum(n))

domenaWords <- left_join(domenaWords, ukupnoWords)


domenaWords %>% head(15)

domenaWords %>% filter(thread.site %in% najveceDomene) %>%
ggplot(., aes(n/totWords, fill = thread.site)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~thread.site, ncol = 2, scales = "free_y")

## Najbitnije riječi po domenma

idf <- domenaWords %>%
  bind_tf_idf(word, thread.site, n)

idf %>% head(10)

idf %>% 
  select(-totWords) %>%
  arrange(desc(tf_idf))

idf %>%
  filter(thread.site %in% najveceDomene5) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  mutate(thread.site = factor(thread.site, levels = najveceDomene5)) %>%
  group_by(thread.site) %>% 
  top_n(10) %>% 
  ungroup() %>%
  ggplot(aes(word, tf_idf, fill = thread.site)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~thread.site, ncol = 2, scales = "free") +
  coord_flip()


```


```{r nGRAMI, message=F, warning=F}


newsCOVID_bigram <- newsCOVID %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

newsCOVID_bigram %>% head(10)


newsCOVID_bigram %>%
  count(bigram, sort = T) %>%
  head(15)

newsCOVID_bigram_sep <- newsCOVID_bigram %>%
  separate(bigram, c("word1","word2"), sep = " ")

newsCOVID_bigram_tidy <- newsCOVID_bigram_sep %>%
  filter(!word1 %in% stop_corpus$word) %>%
  filter(!word2 %in% stop_corpus$word) %>%
  mutate(word1 = gsub("\\d+", NA, word1)) %>%
  mutate(word2 = gsub("\\d+", NA, word2)) %>%
  mutate(word1 = gsub("^[a-zA-Z]$", NA, word1)) %>%
  mutate(word2 = gsub("^[a-zA-Z]$", NA, word2)) %>%
  drop_na()


newsCOVID_bigram_tidy_bigram_counts <- newsCOVID_bigram_tidy %>% 
  count(word1, word2, sort = TRUE)

newsCOVID_bigram_tidy_bigram_counts



bigrams_united <- newsCOVID_bigram_tidy %>%
  drop_na(.) %>%
  unite(bigram, word1, word2, sep = " ")

bigrams_united


bigrams_united %>% 
  count(clanak,bigram,sort = T) -> topicBigram

# Najvažniji bigrami po domenama

 bigram_tf_idf <- bigrams_united %>%
  count(thread.site, bigram) %>%
  bind_tf_idf(bigram, thread.site, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf %>%
  filter(thread.site %in% najveceDomene5) %>%
  arrange(desc(tf_idf)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  mutate(thread.site = factor(thread.site, levels = najveceDomene5)) %>%
  group_by(thread.site) %>% 
  top_n(10) %>% 
  ungroup() %>%
  ggplot(aes(bigram, tf_idf, fill = thread.site)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~thread.site, ncol = 2, scales = "free") +
  coord_flip()

# Analiza bigramskih fraza

newsCOVID_bigram_sep %>%
  filter(word1 == "covid") %>%
  count(word1,word2,sort=T)

# Vizualiziraj bigrame

bigram_graph <- newsCOVID_bigram_tidy_bigram_counts %>%
  filter(n>950) %>%
   graph_from_data_frame()

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

# Korelacije riječi ( R crash na T=30)

newsCOVID_tokenTidy %>% 
  filter(published == "2020-04-22") %>%
  pairwise_count(word, domenaBr, sort = T) %>%
  filter_all(any_vars(!is.na(.))) -> pairsWords

newsCOVID_tokenTidy %>% 
  filter(published > "2020-04-20") %>%
  group_by(word) %>%
  filter(n() > 20) %>%
  filter(!is.na(word)) %>%
  pairwise_cor(word,thread.site, sort = T) -> corsWords

corsWords %>%
  filter(item1 == "oporavak")

corsWords %>%
  filter(item1 %in% c("kriza", "gospodarstvo", "oporavak", "mjere")) %>%
  group_by(item1) %>%
  top_n(8) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ item1, scales = "free") +
  coord_flip()

```



```{r TEME, message=F, warning=F}

newsCOVID_tokenTidy %>%
  count(clanak, word, sort = TRUE) %>%
  cast_dtm(clanak, word,n) -> dtm

newsCOVID_LDA <- LDA(dtm, k = 3,  control = list(seed = 1234))

newsCOVID_LDA_tidy <- tidy(newsCOVID_LDA, matrix = "beta")
newsCOVID_LDA_tidy

newsCOVID_terms <- newsCOVID_LDA_tidy %>%
  drop_na(.) %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

newsCOVID_terms


newsCOVID_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()


# BIgrami topic


topicBigram %>%
  cast_dtm(clanak, bigram,n) -> dtmB

newsCOVID_LDA <- LDA(dtmB, k = 3,  control = list(seed = 1234))

newsCOVID_LDA_tidy <- tidy(newsCOVID_LDA, matrix = "beta")
newsCOVID_LDA_tidy

newsCOVID_terms <- newsCOVID_LDA_tidy %>%
  drop_na(.) %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

newsCOVID_terms


newsCOVID_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() + 
  theme_economist()
```





